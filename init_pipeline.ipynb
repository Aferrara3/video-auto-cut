{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76a9eede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from app.backend.pipeline.transcribe import transcribe_video\n",
    "from app.backend.pipeline.summarize import select_story_segments\n",
    "from app.backend.pipeline.video_utils import concat_clips, cut_segments\n",
    "from app.backend.utils import hash_file, save_pickle, load_pickle\n",
    "from pathlib import Path\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(os.getenv(\"OPENAI_API_KEY\") is not None)\n",
    "print(os.getenv(\"HUGGINGFACE_TOKEN\") is not None)\n",
    "\n",
    "# MATT - Use this to skip the transciprtion and diarization steps if the video exists in cache here (based on hash of video)\n",
    "ENABLE_CACHE = True\n",
    "CACHE_DIR = Path(\"cache\")\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5297ece2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé• Processing: rawfootage_mary(Interview Original).mp4\n",
      "üîë Hash: 6663679a4f42dfc5e059e497045ae07a8421bb707ac8490eeb3e34f417031146\n",
      "üìÅ Outputs will be saved to: artifacts/6663679a4f42dfc5e059e497045ae07a8421bb707ac8490eeb3e34f417031146\n",
      "\n",
      "‚úÖ Using cached SRT text: cache/6663679a4f42dfc5e059e497045ae07a8421bb707ac8490eeb3e34f417031146.srt.pkl\n"
     ]
    }
   ],
   "source": [
    "input_path = \"rawfootage_mary(Interview Original).mp4\"\n",
    "\n",
    "# --- Define the pipeline ---\n",
    "\"\"\"\n",
    "Run AutoCut pipeline with caching on the transcription (SRT) *content*.\n",
    "All downstream artifacts are stored under ./artifacts/<file_hash>/.\n",
    "\"\"\"\n",
    "input_path = Path(input_path)\n",
    "hf_token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "file_hash = hash_file(input_path)\n",
    "\n",
    "base_dir = Path(\"artifacts\") / file_hash\n",
    "base_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cache_path = Path(\"cache\") / f\"{file_hash}.srt.pkl\"\n",
    "\n",
    "print(f\"üé• Processing: {input_path.name}\")\n",
    "print(f\"üîë Hash: {file_hash}\")\n",
    "print(f\"üìÅ Outputs will be saved to: {base_dir}\\n\")\n",
    "\n",
    "# --- Stage 1: Transcription (cached) ---\n",
    "if ENABLE_CACHE and cache_path.exists():\n",
    "    print(f\"‚úÖ Using cached SRT text: {cache_path}\")\n",
    "    srt_text = load_pickle(cache_path)\n",
    "    srt_path = base_dir / \"transcription.srt\"\n",
    "    srt_path.write_text(srt_text, encoding=\"utf-8\")\n",
    "else:\n",
    "    print(\"‚öôÔ∏è Transcribing video with GPU (this may take a while)...\")\n",
    "    srt_path = transcribe_video(input_path, hf_token)\n",
    "\n",
    "    # Read the file text and cache the content\n",
    "    srt_text = Path(srt_path).read_text(encoding=\"utf-8\")\n",
    "    save_pickle(srt_text, cache_path)\n",
    "    print(f\"üíæ Cached SRT text at: {cache_path}\")\n",
    "\n",
    "    # Move it under artifacts/<hash>/ for consistency\n",
    "    new_srt_path = base_dir / \"transcription.srt\"\n",
    "    Path(srt_path).replace(new_srt_path)\n",
    "    srt_path = new_srt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45cc4c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÇÔ∏è Selecting story segments...\n",
      "‚è≥ Calling LLM to select story segments...\n",
      "‚úÖ Saved 16 story segments to artifacts/6663679a4f42dfc5e059e497045ae07a8421bb707ac8490eeb3e34f417031146/transcription.story_segments.json\n"
     ]
    }
   ],
   "source": [
    "# --- Stage 2‚Äì4 ---\n",
    "print(\"\\n‚úÇÔ∏è Selecting story segments...\")\n",
    "story_json = select_story_segments(srt_path, max_duration=120, model=\"gpt-5\")\n",
    "story_json_out = base_dir / \"segments.json\"\n",
    "Path(story_json).replace(story_json_out) if Path(story_json) != story_json_out else None\n",
    "story_json = story_json_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a623c152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéûÔ∏è Cutting segments...\n",
      "‚úÖ clip_01_00-00-28.120_00-00-36.440.mp4\n",
      "‚úÖ clip_02_00-01-08.560_00-01-18.080.mp4\n",
      "‚úÖ clip_03_00-01-19.480_00-01-24.480.mp4\n",
      "‚úÖ clip_04_00-01-25.480_00-01-30.480.mp4\n",
      "‚úÖ clip_05_00-01-32.040_00-01-36.560.mp4\n",
      "‚úÖ clip_06_00-01-38.240_00-01-47.560.mp4\n",
      "‚úÖ clip_07_00-01-49.120_00-01-58.880.mp4\n",
      "‚úÖ clip_08_00-01-59.840_00-02-12.800.mp4\n",
      "‚úÖ clip_09_00-02-14.160_00-02-17.520.mp4\n",
      "‚úÖ clip_10_00-02-28.320_00-02-38.560.mp4\n",
      "‚úÖ clip_11_00-03-01.520_00-03-03.440.mp4\n",
      "‚úÖ clip_12_00-03-11.920_00-03-19.600.mp4\n",
      "‚úÖ clip_13_00-03-20.560_00-03-25.600.mp4\n",
      "‚úÖ clip_14_00-03-29.040_00-03-36.400.mp4\n",
      "‚úÖ clip_15_00-13-28.080_00-13-40.720.mp4\n",
      "‚úÖ clip_16_00-17-05.520_00-17-18.720.mp4\n",
      "üé¨ Concatenating clips...\n",
      "‚úÖ Concatenated 16 clips into artifacts/6663679a4f42dfc5e059e497045ae07a8421bb707ac8490eeb3e34f417031146/final_video.mp4\n",
      "\n",
      "‚úÖ Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"üéûÔ∏è Cutting segments...\")\n",
    "clips_dir = cut_segments(input_path, story_json, output_dir=base_dir / \"clips\")\n",
    "\n",
    "print(\"üé¨ Concatenating clips...\")\n",
    "final_video = concat_clips(clips_dir, output_path=base_dir / \"final_video.mp4\")\n",
    "\n",
    "print(\"\\n‚úÖ Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8a60119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  srt: artifacts/6663679a4f42dfc5e059e497045ae07a8421bb707ac8490eeb3e34f417031146/transcription.srt\n",
      "  segments_json: artifacts/6663679a4f42dfc5e059e497045ae07a8421bb707ac8490eeb3e34f417031146/segments.json\n",
      "  clips_dir: artifacts/6663679a4f42dfc5e059e497045ae07a8421bb707ac8490eeb3e34f417031146/clips\n",
      "  final_video: artifacts/6663679a4f42dfc5e059e497045ae07a8421bb707ac8490eeb3e34f417031146/final_video.mp4\n"
     ]
    }
   ],
   "source": [
    "outputs = {\n",
    "    \"srt\": str(srt_path),\n",
    "    \"segments_json\": str(story_json),\n",
    "    \"clips_dir\": str(clips_dir),\n",
    "    \"final_video\": str(final_video),\n",
    "}\n",
    "\n",
    "for k, v in outputs.items():\n",
    "    print(f\"  {k}: {v}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
